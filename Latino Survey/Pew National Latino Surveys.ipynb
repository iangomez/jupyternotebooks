{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Pew National Latino Surveys\n",
    "by Ian Gomez; \n",
    "11/16/2020\n",
    "\n",
    "\n",
    "\n",
    "In my quest to add data to conversations that often devolve into platitudes or party ideology, I've decided to learn how to navigate public polling datasets. This jupyter notebook is my first attempt at understanding the basics of analyzing Pew survey datasets with python. My primary goals are:\n",
    "- Understanding required libraries\n",
    "- Understanding standard input/output operations\n",
    "- Learning how to store and manipulate survey dataframes\n",
    "- Performing basic analysis with crosstabs\n",
    "- Representing those crosstabs in tabular and graphical forms\n",
    "\n",
    "The data I've chosen is from the Pew Research Center: https://www.pewresearch.org/hispanic/datasets/\n",
    "- 2015 National Latino Survey\n",
    "- 2018 National Latino Survey\n",
    "\n",
    "Eventually, I would like to understand how to responsibly use polling data to gain some insight on how electorate preferences are shaped by public opinion on the issues _and_ the candidates' stances on those issues. \n",
    "\n",
    "For example, if all Democrats in Congress had run on Medicare for all, how many seats would they have gained or lost in the 2020 election? Obviously this is an oversimplified thought experiment, but I'm hoping the answer to such a question could yield a data driven starting point to more robust analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external libraries\n",
    "import pandas as pd\n",
    "import pyreadstat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the survey files into dataframes\n",
    "Use pyreadstat to store them in Pandas dataframes and create a meta data object. The meta object will allow us to get labels, questions, and other useful human readable info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read sav file and create a dict for columns\n",
    "df15, meta15 = pyreadstat.read_sav('latino2015.sav')\n",
    "df18, meta18 = pyreadstat.read_sav('latino2018.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crosstabs\n",
    "Now that we've loaded the data, let's play with the crosstabs. \n",
    "\n",
    "I've picked a three part question from the 2015 National Latino Survey as an example. Question 20 asks, \"In general, how much do you have in common with people in the United States who are each of the following races or origins? \n",
    "- a. Whites\n",
    "- c. Blacks or African Americans\n",
    "- d. Asians or Asian-Americans\"\n",
    "\n",
    "For each part of the question, we'll look at the answer by country of origin/heritage. \n",
    "\n",
    "But first a quick note on how we generate these crosstabs using the default Pandas call and the wrapper I wrote. Note the wrapper won't work when we want to do something different to the data (i.e. take the mean of the data vs summing it). Here are some useful pages:\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html\n",
    "- https://medium.com/@yangdustin5/quick-guide-to-pandas-pivot-table-crosstab-40798b33e367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas crosstab and \"quick_crosstab\"\n",
    "\n",
    "# pd.crosstab(df[answer to question], df[demographic], df.weight, aggfunc=sum, dropna=True, normalize='columns')\n",
    "\n",
    "##### from data\n",
    "# df[answer to question] = index, actual data about how much you have in common\n",
    "# df[demographic]        = columns, country of origin/heritage\n",
    "# df.weight              = weight applied to a particular respondent (to get a more representative sample)\n",
    "\n",
    "##### mapping function calls\n",
    "# .map(meta.xlabels)  # takes meta information and pulls the proper label information out \n",
    "# .map(meta.ylabels)  # a bit of a pain that the labels are not already set up thankfully it's an easy to rememember name (map) \n",
    "\n",
    "##### misc arguments\n",
    "# aggfunc=sum          # Sum answers to question \n",
    "# dropna=True          # Do not include columns whose entries are all NaN (not a number)\n",
    "# normalize='columns'  # Normalize by dividing all values by the sum of values in columns (i.e. create percentages) \n",
    "\n",
    "##### final function calls appended to crosstab\n",
    "# .loc[meta.xlabels.values]         # a selection operation that sorts by index labels\n",
    "# .loc[:,meta.ylabels.values] *100  # a selection operation that sorts by column labels \\\n",
    "                                    #   AND multiplies normalized values to get friendlier percentages \n",
    "\n",
    "\n",
    "def quick_crosstab(df,meta,x,y,weights):\n",
    "    crosstab = pd.crosstab(\n",
    "                            df[x].map(meta.variable_value_labels[x]), \\\n",
    "                            df[y].map(meta.variable_value_labels[y]),  \\\n",
    "                            weights, aggfunc=sum, dropna=True, normalize='columns'\n",
    "                            ). \\\n",
    "                        loc[meta.variable_value_labels[x].values()]. \\\n",
    "                        loc[:,meta.variable_value_labels[y].values()] *100\n",
    "    return(crosstab)  # values in percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = 'q3_combo'  # country of origin/heritage answers\n",
    "\n",
    "ct15_whites = quick_crosstab(df15,meta15,'q20a',demo,df15.weights)  # White Americans\n",
    "ct15_blacks = quick_crosstab(df15,meta15,'q20c',demo,df15.weights)  # Black Americans\n",
    "ct15_asians = quick_crosstab(df15,meta15,'q20d',demo,df15.weights)  # Asian Americans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization \n",
    "\n",
    "The specfied crosstabs have been computed! But they are not very useful until we can see a table or another visualization. Let's use a seaborn heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heat map\n",
    "sns.heatmap(ct15_whites,cmap='rocket')\n",
    "plt.title(\"How much do you have in common with White Americans?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(ct15_blacks,cmap='rocket')\n",
    "plt.title(\"How much do you have in common with African Americans?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(ct15_asians,cmap='rocket')\n",
    "plt.title(\"How much do you have in common with Asian Americans?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 voter enthusiasm by ethinicity\n",
    "ct18_voting = pt.quick_crosstab(df18,meta18,'qn14b','qn3',df18.weight)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
